{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('./')\n",
    "from dataset import tuSimpleDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from models.segnet import SegNet\n",
    "from models.enet import ENet\n",
    "from models.resnet38 import ResNet38\n",
    "from models.bisenet import BiSeNet\n",
    "from models.enet_k import ENet as ENet_k\n",
    "from models.resnet38_k import ResNet38 as ResNet38_k\n",
    "import torchvision\n",
    "from scipy import ndimage as ndi\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "INPUT_CHANNELS = 3\n",
    "OUTPUT_CHANNELS = 2\n",
    "BATCH_SIZE = 5\n",
    "SIZE = [224, 224]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refer from : https://github.com/nyoki-mtl/pytorch-discriminative-loss/blob/master/src/utils.py\n",
    "def coloring(mask):\n",
    "    ins_color_img = np.zeros((mask.shape[0], mask.shape[1], 3), dtype=np.uint8)\n",
    "    n_ins = len(np.unique(mask)) - 1\n",
    "    colors = [plt.cm.Spectral(each) for each in np.linspace(0, 1, n_ins)]\n",
    "    for i in range(n_ins):\n",
    "        ins_color_img[mask == i + 1] =\\\n",
    "            (np.array(colors[i][:3]) * 255).astype(np.uint8)\n",
    "    return ins_color_img\n",
    "\n",
    "def gen_instance_mask(sem_pred, ins_pred, n_obj):\n",
    "    embeddings = ins_pred[:, sem_pred].transpose(1, 0)\n",
    "#     clustering = KMeans(n_obj).fit(embeddings)\n",
    "    clustering = DBSCAN(eps=0.05).fit(embeddings)\n",
    "    labels = clustering.labels_\n",
    "\n",
    "    instance_mask = np.zeros_like(sem_pred, dtype=np.uint8)\n",
    "    for i in range(n_obj):\n",
    "        lbl = np.zeros_like(labels, dtype=np.uint8)\n",
    "        lbl[labels == i] = i + 1\n",
    "        instance_mask[sem_pred] += lbl\n",
    "\n",
    "    return instance_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_mask(sem_labels, a=3):\n",
    "    lst = []\n",
    "    for i in list(range(-a, a)):\n",
    "        for j in list(range(-a, a)):\n",
    "            if i**2+j**2<=a**2:\n",
    "                lst.append(torchvision.transforms.functional.affine(sem_labels ,translate=(i,j),angle=0,scale=1,shear=0))\n",
    "    msk = lst[0]\n",
    "    for msks in lst:\n",
    "        msk += msks\n",
    "    msk[msk>1]=1\n",
    "    return msk\n",
    "def eval_loss(filename = 'enet_model_best', shuffle=False, model = 'enet', data_part = 'test', expand_dim=3, split_train=False, data_num=100, soft=True, seed=None, loss_func='MSE'):\n",
    "    if data_part=='train':\n",
    "        test_path = '../TUSimple/train_set'\n",
    "    else:\n",
    "        test_path = '../TUSimple/test_set'\n",
    "    # MODEL_PATH = '../model_best_enet.pth'\n",
    "    MODEL_PATH = f'results/{filename}.pth'\n",
    "    test_dataset = tuSimpleDataset(test_path, size=SIZE, train=True)\n",
    "    if data_part=='train' and split_train==True:\n",
    "      train_len = int(len(test_dataset)*0.8)\n",
    "      if seed is not None:\n",
    "         torch.manual_seed(seed)\n",
    "      _, test_dataset = torch.utils.data.random_split(test_dataset, [train_len, len(test_dataset)-train_len])\n",
    "    test_dataset = torch.utils.data.Subset(test_dataset, list(range(data_num)))\n",
    "    test_dataloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=shuffle, num_workers=8)\n",
    "    if model == 'enet': \n",
    "       model = ENet(input_ch=INPUT_CHANNELS, output_ch=OUTPUT_CHANNELS).cuda()\n",
    "    if model == 'segnet':\n",
    "       model = SegNet(input_ch=INPUT_CHANNELS, output_ch=OUTPUT_CHANNELS).cuda()\n",
    "    if model == 'enet_k': \n",
    "       model = ENet_k(input_ch=INPUT_CHANNELS, output_ch=OUTPUT_CHANNELS).cuda()\n",
    "    if model == 'resnet38': \n",
    "       model = ResNet38().cuda()\n",
    "    if model == 'bisenet': \n",
    "       model = BiSeNet(32, 'resnet18').cuda()\n",
    "    if model == 'resnet38_k': \n",
    "       model = ResNet38_k().cuda()\n",
    "\n",
    "    model.load_state_dict(torch.load(MODEL_PATH))\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for imgs, sem_labels, ins_labels in test_dataloader:\n",
    "    #imgs, sem_labels, ins_labels = next(iter(test_dataloader))\n",
    "      sem_labels_exp = expand_mask(sem_labels, expand_dim)\n",
    "      \n",
    "      input_tensor = torch.autograd.Variable(imgs).cuda()\n",
    "      sem_pred_, ins_pred_ = model(input_tensor)\n",
    "      images = input_tensor.permute(0,2,3,1).contiguous().cpu().data.numpy()\n",
    "      images = np.array(images, dtype=np.uint8)\n",
    "      sem_pred = sem_pred_[:,1,:,:].cpu().data.numpy()\n",
    "      #  print(sem_pred, np.max(sem_pred))\n",
    "      ins_pred = ins_pred_.cpu().data.numpy()\n",
    "      p_sem_pred = []\n",
    "      for sp in sem_pred:\n",
    "         p_sem_pred.append(ndi.morphology.binary_fill_holes(sp > 0.5))\n",
    "      p_sem_pred = torch.tensor(p_sem_pred).float()\n",
    "      sem_labels_soft = p_sem_pred*sem_labels_exp+sem_labels\n",
    "      sem_labels_soft[sem_labels_soft>1]=1\n",
    "      if loss_func == 'MSE':\n",
    "         criterion = torch.nn.MSELoss().cuda()\n",
    "      if loss_func == 'CE':\n",
    "         criterion = torch.nn.CrossEntropyLoss().cuda()\n",
    "         sem_labels_soft = sem_labels_soft.float()\n",
    "         sem_labels = sem_labels.float()\n",
    "   \n",
    "      if soft:\n",
    "         loss = criterion(p_sem_pred, sem_labels_soft)\n",
    "      else:\n",
    "         loss = criterion(p_sem_pred, sem_labels)\n",
    "      losses.append(loss.item())\n",
    "    print(np.mean(losses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.017807517619803547\n",
      "0.012315250327810645\n"
     ]
    }
   ],
   "source": [
    "eval_loss('segnet_model_best', model='segnet', data_part='test', data_num=100, soft=False)\n",
    "eval_loss('segnet_model_best', model='segnet', data_part='test', data_num=100, soft=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02105727819725871\n",
      "0.017245695134624837\n"
     ]
    }
   ],
   "source": [
    "eval_loss('enet_model_best', model='enet', data_part='test', data_num=100, soft=False)\n",
    "eval_loss('enet_model_best', model='enet', data_part='test', data_num=100, soft=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02461934005841613\n",
      "0.01087292719166726\n"
     ]
    }
   ],
   "source": [
    "eval_loss('enet_weight_model_best', model='enet', data_part='test', data_num=100, soft=False)\n",
    "eval_loss('enet_weight_model_best', model='enet', data_part='test', data_num=100, soft=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.023065808322280647\n",
      "0.016902901930734515\n"
     ]
    }
   ],
   "source": [
    "eval_loss('enet_k_model_best_train', model='enet_k', data_part='test', data_num=100, soft=False)\n",
    "eval_loss('enet_k_model_best_train', model='enet_k', data_part='test', data_num=100, soft=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.029070471972227098\n",
      "0.011401068232953549\n"
     ]
    }
   ],
   "source": [
    "eval_loss('enet_k_weight_model_best_train', model='enet_k', data_part='test', data_num=100, soft=False)\n",
    "eval_loss('enet_k_weight_model_best_train', model='enet_k', data_part='test', data_num=100, soft=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025105229578912258\n",
      "0.010416334494948387\n"
     ]
    }
   ],
   "source": [
    "eval_loss('enet_0.1_weight_model_best_train', model='enet', data_part='test', data_num=100, soft=False)\n",
    "eval_loss('enet_0.1_weight_model_best_train', model='enet', data_part='test', data_num=100, soft=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02277264026924968\n",
      "0.012506776209920644\n"
     ]
    }
   ],
   "source": [
    "eval_loss('enet_k_0.1_weight_model_best_train', model='enet_k', data_part='test', data_num=100, soft=False)\n",
    "eval_loss('enet_k_0.1_weight_model_best_train', model='enet_k', data_part='test', data_num=100, soft=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.018891502125188708\n",
      "0.014070272678509355\n"
     ]
    }
   ],
   "source": [
    "eval_loss('resnet38_model_best_train', model='resnet38', data_part='test', data_num=100, soft=False)\n",
    "eval_loss('resnet38_model_best_train', model='resnet38', data_part='test', data_num=100, soft=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.019853914296254514\n",
      "0.010670639271847904\n"
     ]
    }
   ],
   "source": [
    "eval_loss('resnet38_weight_0.1_model_best_train', model='resnet38', data_part='test', data_num=100, soft=False)\n",
    "eval_loss('resnet38_weight_0.1_model_best_train', model='resnet38', data_part='test', data_num=100, soft=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02053770739585161\n",
      "0.014867267338559031\n"
     ]
    }
   ],
   "source": [
    "eval_loss('resnet38_k_model_best_train', model='resnet38_k', data_part='test', data_num=100, soft=False)\n",
    "eval_loss('resnet38_k_model_best_train', model='resnet38_k', data_part='test', data_num=100, soft=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.022987484093755485\n",
      "0.010872130002826452\n"
     ]
    }
   ],
   "source": [
    "eval_loss('resnet38_k_weight_0.1_model_best_train', model='resnet38_k', data_part='test', data_num=100, soft=False)\n",
    "eval_loss('resnet38_k_weight_0.1_model_best_train', model='resnet38_k', data_part='test', data_num=100, soft=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
